{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis on COVID-19 related Tweets (TF-IDF).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcq7gT08ran8"
      },
      "source": [
        "# **Sentiment Analysis on COVID-19 related Tweets (Machine Learning: TF-IDF)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMcGNHpNv1PN",
        "outputId": "7a05f1b5-611d-4d15-ac80-23e7f1bb2af5"
      },
      "source": [
        "# We have to mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4sG-3Wn8fSI"
      },
      "source": [
        "#**Import Files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VXxLSK8_raoB",
        "outputId": "b1a75aa4-889a-4f94-bc57-020313e5089e"
      },
      "source": [
        "import base64\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "#Plotly imports\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objects as go\n",
        "import plotly.tools as tls\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "\n",
        "# Other imports\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "%matplotlib notebook"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVF40njtraoD"
      },
      "source": [
        "#**Reading CSV File**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "TKsk-vabraoD",
        "outputId": "f35d8a2d-8a89-42fb-9ce6-6a85ae58017f"
      },
      "source": [
        "#TextBlob\n",
        "#train=pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/Text_Blob_PolarityAnalysis.csv')\n",
        "#Original 45,007\n",
        "#train=pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/COVID-19MasterFinalDataset.csv')\n",
        "#36k Tweets\n",
        "#train=pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/36kCleanedCOVID-19MasterFinalDataset.csv')\n",
        "#36k Tweets\n",
        "\n",
        "train=pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/SentimentAnalysisCOVID-19MasterFinalDataset.csv')\n",
        "train.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Tweets</th>\n",
              "      <th>Translated</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mar</td>\n",
              "      <td>Me to COVID-19:  pic.twitter.com/OLX9LTjTsW</td>\n",
              "      <td>me to covid</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>May</td>\n",
              "      <td>So many realizations during ECQ because of COV...</td>\n",
              "      <td>so many realizations during ecq because of cov...</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>Positive</td>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mar</td>\n",
              "      <td>Murag sure pko na magka covid kesa magbalik mi...</td>\n",
              "      <td>it's like a covid covid kesa back to cejay hah...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>Positive</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Apr</td>\n",
              "      <td>While we are all fighting against COVID-19, me...</td>\n",
              "      <td>while we are all fighting against covid meanwh...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mar</td>\n",
              "      <td>Taong bahay, dahil sa covid-19üò¥</td>\n",
              "      <td>person house because of covid</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Mar</td>\n",
              "      <td>mamamatay ata ako sa stress, hindi sa covid.</td>\n",
              "      <td>I will die in stress not in covid</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Jun</td>\n",
              "      <td>I want to join kaso may pangamba pa rin ng COV...</td>\n",
              "      <td>I Want To Join Case There is still a covid</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Mar</td>\n",
              "      <td>So gi confiscate ang akuang alcohol na 75mL, u...</td>\n",
              "      <td>So confiscate the Akuang Alcohol ML then the w...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Apr</td>\n",
              "      <td>I choose you to be a positive from covid 19 ch...</td>\n",
              "      <td>i choose you to be a positive from covid  char...</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>Positive</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Apr</td>\n",
              "      <td>Jgh, then ligo. Grabe covid stop na. ü§∑üèª‚Äç‚ôÇÔ∏èüôè</td>\n",
              "      <td>jgh then ligo grabe covid stop na ü§∑</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Date                                             Tweets  ... Sentiment  length\n",
              "0  Mar        Me to COVID-19:  pic.twitter.com/OLX9LTjTsW  ...   Neutral      11\n",
              "1  May  So many realizations during ECQ because of COV...  ...  Positive     153\n",
              "2  Mar  Murag sure pko na magka covid kesa magbalik mi...  ...  Positive      51\n",
              "3  Apr  While we are all fighting against COVID-19, me...  ...   Neutral     112\n",
              "4  Mar                    Taong bahay, dahil sa covid-19üò¥  ...   Neutral      29\n",
              "5  Mar       mamamatay ata ako sa stress, hindi sa covid.  ...   Neutral      33\n",
              "6  Jun  I want to join kaso may pangamba pa rin ng COV...  ...   Neutral      42\n",
              "7  Mar  So gi confiscate ang akuang alcohol na 75mL, u...  ...   Neutral      62\n",
              "8  Apr  I choose you to be a positive from covid 19 ch...  ...  Positive      53\n",
              "9  Apr        Jgh, then ligo. Grabe covid stop na. ü§∑üèª‚Äç‚ôÇÔ∏èüôè  ...   Neutral      35\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUILANUnRFds",
        "outputId": "4b4ee5d0-b018-4743-f096-413e6b25a6a9"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44709, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nOqBzNlQU2Q"
      },
      "source": [
        "# **Choose Translated Tweet and its Polarity**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "LSE09rU-raoE",
        "outputId": "21106a4d-6ad1-498c-ac18-9aa6034c85c9"
      },
      "source": [
        "new_data = train[['Translated','Sentiment']]\n",
        "new_data.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Translated</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>me to covid</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>so many realizations during ecq because of cov...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it's like a covid covid kesa back to cejay hah...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>while we are all fighting against covid meanwh...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>person house because of covid</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I will die in stress not in covid</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I Want To Join Case There is still a covid</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>So confiscate the Akuang Alcohol ML then the w...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>i choose you to be a positive from covid  char...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>jgh then ligo grabe covid stop na ü§∑</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>secretary  presents the agencys preliminary as...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>happy birthday to my favorite hooman i miss th...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>The Way of the Cross is still in the Shrine of...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>conducted info dissemination re covid at bound...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>may have finished counting covid so that every...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>mayor climaco analyzing the location of the ho...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Hope all you are just ahahahahahahahahahahah n...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Eto no tribulation is two no matter what payan...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Now you say that you cared for the frontliners...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>online discussion on the role of the social sc...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Translated Sentiment\n",
              "0                                         me to covid   Neutral\n",
              "1   so many realizations during ecq because of cov...  Positive\n",
              "2   it's like a covid covid kesa back to cejay hah...  Positive\n",
              "3   while we are all fighting against covid meanwh...   Neutral\n",
              "4                       person house because of covid   Neutral\n",
              "5                   I will die in stress not in covid   Neutral\n",
              "6          I Want To Join Case There is still a covid   Neutral\n",
              "7   So confiscate the Akuang Alcohol ML then the w...   Neutral\n",
              "8   i choose you to be a positive from covid  char...  Positive\n",
              "9                 jgh then ligo grabe covid stop na ü§∑   Neutral\n",
              "10  secretary  presents the agencys preliminary as...   Neutral\n",
              "11  happy birthday to my favorite hooman i miss th...  Positive\n",
              "12  The Way of the Cross is still in the Shrine of...   Neutral\n",
              "13  conducted info dissemination re covid at bound...   Neutral\n",
              "14  may have finished counting covid so that every...   Neutral\n",
              "15  mayor climaco analyzing the location of the ho...   Neutral\n",
              "16  Hope all you are just ahahahahahahahahahahah n...  Positive\n",
              "17  Eto no tribulation is two no matter what payan...  Positive\n",
              "18  Now you say that you cared for the frontliners...  Positive\n",
              "19  online discussion on the role of the social sc...  Positive"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "sEbH12ACtspi",
        "outputId": "35cbbb93-19bf-440c-ebf2-b9ff549ada08"
      },
      "source": [
        "def convert_label(sentiment):\n",
        " \n",
        "  for i in range(len(new_data)):\n",
        "    if sentiment == \"Negative\":\n",
        "      return -1;\n",
        "    elif sentiment == \"Neutral\":\n",
        "      return 0;\n",
        "    elif sentiment == \"Positive\":\n",
        "      return 1;\n",
        "\n",
        "new_data[\"Analysis\"] = new_data[\"Sentiment\"].apply(convert_label)  \n",
        "new_data.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Translated</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Analysis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>me to covid</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>so many realizations during ecq because of cov...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it's like a covid covid kesa back to cejay hah...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>while we are all fighting against covid meanwh...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>person house because of covid</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Translated Sentiment  Analysis\n",
              "0                                        me to covid   Neutral         0\n",
              "1  so many realizations during ecq because of cov...  Positive         1\n",
              "2  it's like a covid covid kesa back to cejay hah...  Positive         1\n",
              "3  while we are all fighting against covid meanwh...   Neutral         0\n",
              "4                      person house because of covid   Neutral         0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbKaAbwRraoI"
      },
      "source": [
        "#**Data Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88rActrXraoI",
        "outputId": "48cb5356-93b4-441d-cadd-57a955db85ec"
      },
      "source": [
        "print('Dataset size:',new_data.shape)\n",
        "print('Columns are:',new_data.columns)\n",
        "new_data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: (44709, 3)\n",
            "Columns are: Index(['Translated', 'Sentiment', 'Analysis'], dtype='object')\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 44709 entries, 0 to 44708\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Translated  44709 non-null  object\n",
            " 1   Sentiment   44709 non-null  object\n",
            " 2   Analysis    44709 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 1.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bOr8s14OeLk"
      },
      "source": [
        "# **Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YczDpZW-_Vxs"
      },
      "source": [
        "# **Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4_KXiTi_iz4"
      },
      "source": [
        "X = new_data['Translated'] \n",
        "y = new_data['Sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tffnDDEb_r3A"
      },
      "source": [
        "processed_tweets = []\n",
        "\n",
        "for new_data in range(0, len(X)):  \n",
        "    # Remove all the special characters\n",
        "    processed_tweet = re.sub(r'\\W', ' ', str(X[new_data]))\n",
        "\n",
        "    # remove all single characters\n",
        "    processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n",
        "\n",
        "    # Remove single characters from the start\n",
        "    processed_tweet = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_tweet) \n",
        "\n",
        "    # Substituting multiple spaces with single space\n",
        "    processed_tweet= re.sub(r'\\s+', ' ', processed_tweet, flags=re.I)\n",
        "\n",
        "    # Removing prefixed 'b'\n",
        "    processed_tweet = re.sub(r'^b\\s+', '', processed_tweet)\n",
        "\n",
        "    # Converting to Lowercase\n",
        "    processed_tweet = processed_tweet.lower()\n",
        "\n",
        "    processed_tweets.append(processed_tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR5iOzcaraoN"
      },
      "source": [
        "# **Data Pre-preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heWOyaSlQeOv"
      },
      "source": [
        "# **Stop-words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWhQ1gbt_vmZ",
        "outputId": "d0f3cdd4-2cf5-4d27-a9cb-c155ff99cfdc"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop_words_senti = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgDMRorGraoO"
      },
      "source": [
        "## **TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1ssECbT_-KF"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
        "\n",
        "tfidfconverter = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.7, stop_words=stop_words_senti) \n",
        "#tfidfconverter = TfidfVectorizer() \n",
        "X = tfidfconverter.fit_transform(processed_tweets).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMfboBgyADKg"
      },
      "source": [
        "# **Train Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X487DV_9_-7A"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xrq6Z7_3AySm"
      },
      "source": [
        "# **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVNdGJFHAAss",
        "outputId": "008125f8-d404-4f1b-8254-aff22e34a34c"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=50)  \n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "predictions_randomforest = random_forest.predict(X_test)\n",
        "  \n",
        "print(confusion_matrix(y_test,predictions_randomforest ))\n",
        "print(classification_report(y_test,predictions_randomforest))\n",
        "print('Accuracy Score: ',accuracy_score(y_test, predictions_randomforest))\n",
        "print('Train Accuracy Score: ',random_forest.score(X_train,y_train))\n",
        "print('Test Accuracy Score: ',random_forest.score(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1141  173  253]\n",
            " [  14 3493   53]\n",
            " [  88  203 3524]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.92      0.73      0.81      1567\n",
            "     Neutral       0.90      0.98      0.94      3560\n",
            "    Positive       0.92      0.92      0.92      3815\n",
            "\n",
            "    accuracy                           0.91      8942\n",
            "   macro avg       0.91      0.88      0.89      8942\n",
            "weighted avg       0.91      0.91      0.91      8942\n",
            "\n",
            "Accuracy Score:  0.9123238649071796\n",
            "Train Accuracy Score:  0.9942964184863142\n",
            "Test Accuracy Score:  0.9123238649071796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRClXVDrEVy0"
      },
      "source": [
        "# **Multinomial Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrIjozBZEbvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d7d4b7-0df0-4a02-cb03-7b4306a8f684"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "mnb= MultinomialNB(alpha = 0.003).fit(X_train, y_train)\n",
        "\n",
        "predictions_mnb = mnb.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,predictions_mnb))  \n",
        "print(classification_report(y_test,predictions_mnb))  \n",
        "print('Accuracy Score: ',accuracy_score(y_test, predictions_mnb))\n",
        "print('Train Accuracy Score: ',mnb.score(X_train,y_train))\n",
        "print('Test Accuracy Score: ',mnb.score(X_test,y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 616  247  704]\n",
            " [  18 2683  859]\n",
            " [  43  308 3464]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.91      0.39      0.55      1567\n",
            "     Neutral       0.83      0.75      0.79      3560\n",
            "    Positive       0.69      0.91      0.78      3815\n",
            "\n",
            "    accuracy                           0.76      8942\n",
            "   macro avg       0.81      0.68      0.71      8942\n",
            "weighted avg       0.78      0.76      0.74      8942\n",
            "\n",
            "Accuracy Score:  0.7563184969805412\n",
            "Train Accuracy Score:  0.7886599379316129\n",
            "Test Accuracy Score:  0.7563184969805412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVlgpEEXB8gc"
      },
      "source": [
        "# **Linear Support Vector Machine**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhYMOGY2A28i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93871a84-8ab6-4c6a-8cb9-29ade31617a4"
      },
      "source": [
        "from sklearn.svm import LinearSVC \n",
        "\n",
        "linSVC = LinearSVC(C= 1.0, loss= 'squared_hinge', max_iter= 10000, penalty= 'l2', multi_class='crammer_singer', random_state = 500) \n",
        "linSVC.fit(X_train, y_train) \n",
        "\n",
        "predictions_linSVC = linSVC.predict(X_test)\n",
        " \n",
        "    \n",
        "print(confusion_matrix(y_test,predictions_linSVC))  \n",
        "print(classification_report(y_test,predictions_linSVC))  \n",
        "print('Accuracy Score: ',accuracy_score(y_test, predictions_linSVC))\n",
        "print('Train Accuracy Score: ',linSVC.score(X_train,y_train))\n",
        "print('Test Accuracy Score: ',linSVC.score(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1083  254  230]\n",
            " [  26 3492   42]\n",
            " [ 123  352 3340]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.88      0.69      0.77      1567\n",
            "     Neutral       0.85      0.98      0.91      3560\n",
            "    Positive       0.92      0.88      0.90      3815\n",
            "\n",
            "    accuracy                           0.89      8942\n",
            "   macro avg       0.89      0.85      0.86      8942\n",
            "weighted avg       0.89      0.89      0.88      8942\n",
            "\n",
            "Accuracy Score:  0.8851487363006039\n",
            "Train Accuracy Score:  0.8909609416501244\n",
            "Test Accuracy Score:  0.8851487363006039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQGtbW6bCNxU"
      },
      "source": [
        "# **Multi-class Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI1EP05HB4Eu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a071565-7551-47fe-9d52-e908d681401c"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#logRes = LogisticRegression(C=0.6, class_weight='balanced',multi_class='multinomial',max_iter=100,random_state=0)\n",
        "logRes = LogisticRegression(C=0.6, multi_class='multinomial',max_iter=100,random_state=0)\n",
        "logRes.fit(X_train, y_train)\n",
        " \n",
        "predictions_logRes = logRes.predict(X_test)\n",
        "    \n",
        "print(confusion_matrix(y_test,predictions_logRes))    \n",
        "print(classification_report(y_test,predictions_logRes ))  \n",
        "print('Accuracy Score: ',accuracy_score(y_test, predictions_logRes ))\n",
        "print('Train Accuracy Score: ',logRes.score(X_train,y_train))\n",
        "print('Test Accuracy Score: ',logRes.score(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 927  339  301]\n",
            " [  15 3449   96]\n",
            " [  95  381 3339]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.89      0.59      0.71      1567\n",
            "     Neutral       0.83      0.97      0.89      3560\n",
            "    Positive       0.89      0.88      0.88      3815\n",
            "\n",
            "    accuracy                           0.86      8942\n",
            "   macro avg       0.87      0.81      0.83      8942\n",
            "weighted avg       0.87      0.86      0.86      8942\n",
            "\n",
            "Accuracy Score:  0.8627823753075374\n",
            "Train Accuracy Score:  0.879833365951855\n",
            "Test Accuracy Score:  0.8627823753075374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEH_-o54CoOp"
      },
      "source": [
        "# **Adaboost Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhCamlyYCgnT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "996d3bad-97d6-47ed-f90b-7fbcf85ccee5"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "abc = AdaBoostClassifier(n_estimators = 300, learning_rate = 1)\n",
        "abc.fit(X_train, y_train)\n",
        " \n",
        "predictions_abc = abc.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,predictions_abc))  \n",
        "print(classification_report(y_test,predictions_abc))  \n",
        "print('Accuracy Score: ',accuracy_score(y_test, predictions_abc))\n",
        "print('Train Accuracy Score: ',abc.score(X_train,y_train))\n",
        "print('Test Accuracy Score: ',abc.score(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-581de1ffafc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mabc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpredictions_abc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \"\"\"\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31ZV6ofeC1e5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}