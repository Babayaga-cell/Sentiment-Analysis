{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Deep_Learning_with_GloVe Word Embedding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XTs5L4klFUX"
      },
      "source": [
        "# **Sentiment Analysis on COVID-19 related Tweets (Deep Learning: LSTM with GloVe: Global Vectors for Word Representation)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clgGjs8DLJKC"
      },
      "source": [
        "*   Dataset: SentimentAnalysisCOVID-19MasterFinalDataset.csv\n",
        "*   Runtime Type: GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnNBgVcjlY-n"
      },
      "source": [
        "# Mounting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HU6SPREvy1v",
        "outputId": "13a31062-7262-40cd-902a-52e45afd7b2e"
      },
      "source": [
        "# We have to mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivYo63UTlbuH"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08QxW_VXv4Ti"
      },
      "source": [
        "#library imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import spacy\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import string\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd122TFTleif"
      },
      "source": [
        "# Reading the Dataset with Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "DPEVwl-av5vm",
        "outputId": "8ae5a41f-4a03-430a-f660-df1c8a9e9b68"
      },
      "source": [
        "#Read CSV from Pandas for Data Analysis\n",
        "import pandas as pd\n",
        "\n",
        "f = open('gdrive/My Drive/Colab Notebooks/SentimentAnalysisCOVID-19MasterFinalDataset.csv','rU')   \n",
        "df = pd.read_csv(f)\n",
        "df = df[['Translated','Sentiment']]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: 'U' mode is deprecated\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Translated</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>me to covid</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>so many realizations during ecq because of cov...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it's like a covid covid kesa back to cejay hah...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>while we are all fighting against covid meanwh...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>person house because of covid</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Translated Sentiment\n",
              "0                                        me to covid   Neutral\n",
              "1  so many realizations during ecq because of cov...  Positive\n",
              "2  it's like a covid covid kesa back to cejay hah...  Positive\n",
              "3  while we are all fighting against covid meanwh...   Neutral\n",
              "4                      person house because of covid   Neutral"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFTno6E_loQ5"
      },
      "source": [
        "Shape of the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2DE_HJ-wHPI",
        "outputId": "8c14336b-ede0-4151-acd0-50870d88898f"
      },
      "source": [
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(44709, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZWkCH9plsje"
      },
      "source": [
        "Convert Word Label to Numerical Label\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2oIAI7ewPKh"
      },
      "source": [
        "def convert_label(polarity):\n",
        "  polarity.lower()\n",
        "  for i in range(len(df)):\n",
        "    if polarity == \"Negative\":\n",
        "      return 0;\n",
        "    elif polarity == \"Neutral\":\n",
        "      return 1;\n",
        "    elif polarity == \"Positive\":\n",
        "      return 2;\n",
        "\n",
        "df[\"Analysis\"] = df[\"Sentiment\"].apply(convert_label) \n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "iDxO9NP-wdL5",
        "outputId": "7fc720a3-7b43-4203-aa8e-7ade11047bd3"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Translated</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Analysis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>me to covid</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>so many realizations during ecq because of cov...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it's like a covid covid kesa back to cejay hah...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>while we are all fighting against covid meanwh...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>person house because of covid</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44704</th>\n",
              "      <td>from  as of june   pm confirmed cases of covid...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44705</th>\n",
              "      <td>Boi Dabest really listen to martal covid covid...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44706</th>\n",
              "      <td>The worst Teacher is the one who is boggy with...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44707</th>\n",
              "      <td>Chaka Na Nko The Effect of Covid Does I say I ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44708</th>\n",
              "      <td>confirmed covid case in zamboanga city hanuna</td>\n",
              "      <td>Positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44709 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Translated Sentiment  Analysis\n",
              "0                                            me to covid   Neutral         1\n",
              "1      so many realizations during ecq because of cov...  Positive         2\n",
              "2      it's like a covid covid kesa back to cejay hah...  Positive         2\n",
              "3      while we are all fighting against covid meanwh...   Neutral         1\n",
              "4                          person house because of covid   Neutral         1\n",
              "...                                                  ...       ...       ...\n",
              "44704  from  as of june   pm confirmed cases of covid...  Positive         2\n",
              "44705  Boi Dabest really listen to martal covid covid...  Positive         2\n",
              "44706  The worst Teacher is the one who is boggy with...  Negative         0\n",
              "44707  Chaka Na Nko The Effect of Covid Does I say I ...   Neutral         1\n",
              "44708      confirmed covid case in zamboanga city hanuna  Positive         2\n",
              "\n",
              "[44709 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzSnuBVIl0cM"
      },
      "source": [
        "# Cleaning of the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FbZdBNSl-eK"
      },
      "source": [
        "Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KWuKNjBxc7S",
        "outputId": "e036a3c1-de92-4830-daf4-dc02f4f8e340"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stopword = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRAwquUNl_zX"
      },
      "source": [
        "Cleaning the noise of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "B9zy8ThVzLCS",
        "outputId": "a472ade6-f6f5-46ca-8b32-83ed135e9fb0"
      },
      "source": [
        "def cleanTxt(text):\n",
        "  text = re.sub(r'@[A-Za-z0-9]+','',text) #remove @mentions\n",
        "  text = re.sub(r'#','', text) #removing the '#' symbol\n",
        "  text = re.sub(r'RT[\\s]+','', text) #Removing RT\n",
        "  text = re.sub(r'https?:\\/\\/\\S+', '',text) #remove the hyper link\n",
        "  text = re.sub('([^A-Za-z\\ ])','',text) #removes everything and keeps only letters\n",
        "  text = text.lower() #transforms everything to lowercase\n",
        "  text = [word for word in text.split() if text.lower() not in stopword] #removes stopwords\n",
        "  text = ' '.join(text)\n",
        "  return text\n",
        "\n",
        "df['Translated'] = df['Translated'].apply(cleanTxt)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Translated</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Analysis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>me to covid</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>so many realizations during ecq because of cov...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>its like a covid covid kesa back to cejay haha...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>while we are all fighting against covid meanwh...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>person house because of covid</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Translated Sentiment  Analysis\n",
              "0                                        me to covid   Neutral         1\n",
              "1  so many realizations during ecq because of cov...  Positive         2\n",
              "2  its like a covid covid kesa back to cejay haha...  Positive         2\n",
              "3  while we are all fighting against covid meanwh...   Neutral         1\n",
              "4                      person house because of covid   Neutral         1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7dwCA9amFGH"
      },
      "source": [
        "Generate the Length of each row in the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "BBK9uf9BzRZy",
        "outputId": "0f48255c-63a3-4f2c-a628-bc9fbc224278"
      },
      "source": [
        "df['length'] = df['Translated'].apply(lambda x: len(x))\n",
        "df = df[['Translated', 'Analysis','length']]\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Translated</th>\n",
              "      <th>Analysis</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>me to covid</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>so many realizations during ecq because of cov...</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>its like a covid covid kesa back to cejay haha...</td>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>while we are all fighting against covid meanwh...</td>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>person house because of covid</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Translated  Analysis  length\n",
              "0                                        me to covid         1      11\n",
              "1  so many realizations during ecq because of cov...         2     153\n",
              "2  its like a covid covid kesa back to cejay haha...         2      50\n",
              "3  while we are all fighting against covid meanwh...         1     106\n",
              "4                      person house because of covid         1      29"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_NU_tKdmNKg"
      },
      "source": [
        "Count number of occurences of each word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruGuVcJjzlvV"
      },
      "source": [
        "#count number of occurences of each word\n",
        "counts = Counter()\n",
        "for index, row in df.iterrows():\n",
        "    counts.update(row['Translated'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSjDFmjjzoi7"
      },
      "source": [
        "vocab2index = {\"\":0, \"UNK\":1}\n",
        "words = [\"\", \"UNK\"]\n",
        "for word in counts:\n",
        "    vocab2index[word] = len(words)\n",
        "    words.append(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nsSi2zjmT8C"
      },
      "source": [
        "Encode the Data from Words to Numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5p1hufYKbIb"
      },
      "source": [
        "def encode_sentence(text, vocab2index, N=42):\n",
        "    encoded = np.zeros(N, dtype=int)\n",
        "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in text])\n",
        "    length = min(N, len(enc1))\n",
        "    encoded[:length] = enc1[:length]\n",
        "    return encoded, length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "-gdoV5vXKdBH",
        "outputId": "597d208e-e6d4-489a-c4df-c25bd9325107"
      },
      "source": [
        "df['Encoded'] = df['Translated'].apply(lambda x: np.array(encode_sentence(x,vocab2index)))\n",
        "df.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Translated</th>\n",
              "      <th>Analysis</th>\n",
              "      <th>length</th>\n",
              "      <th>Encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>me to covid</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>[[2, 3, 4, 5, 6, 4, 7, 6, 8, 9, 10, 0, 0, 0, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>so many realizations during ecq because of cov...</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>[[11, 6, 4, 2, 12, 13, 14, 4, 15, 3, 12, 16, 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>its like a covid covid kesa back to cejay haha...</td>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>[[9, 5, 11, 4, 16, 9, 23, 3, 4, 12, 4, 7, 6, 8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>while we are all fighting against covid meanwh...</td>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "      <td>[[24, 25, 9, 16, 3, 4, 24, 3, 4, 12, 15, 3, 4,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>person house because of covid</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>[[26, 3, 15, 11, 6, 13, 4, 25, 6, 18, 11, 3, 4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i will die in stress not in covid</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>[[9, 4, 24, 9, 16, 16, 4, 10, 9, 3, 4, 9, 13, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>i want to join case there is still a covid</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>[[9, 4, 24, 12, 13, 5, 4, 5, 6, 4, 27, 6, 9, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>so confiscate the akuang alcohol ml then the w...</td>\n",
              "      <td>1</td>\n",
              "      <td>62</td>\n",
              "      <td>[[11, 6, 4, 7, 6, 13, 22, 9, 11, 7, 12, 5, 3, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>i choose you to be a positive from covid charrr</td>\n",
              "      <td>2</td>\n",
              "      <td>47</td>\n",
              "      <td>[[9, 4, 7, 25, 6, 6, 11, 3, 4, 14, 6, 18, 4, 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>jgh then ligo grabe covid stop na</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>[[27, 19, 25, 4, 5, 25, 3, 13, 4, 16, 9, 19, 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>secretary presents the agencys preliminary ass...</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>[[11, 3, 7, 15, 3, 5, 12, 15, 14, 4, 26, 15, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>happy birthday to my favorite hooman i miss th...</td>\n",
              "      <td>2</td>\n",
              "      <td>222</td>\n",
              "      <td>[[25, 12, 26, 26, 14, 4, 21, 9, 15, 5, 25, 10,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>the way of the cross is still in the shrine of...</td>\n",
              "      <td>1</td>\n",
              "      <td>219</td>\n",
              "      <td>[[5, 25, 3, 4, 24, 12, 14, 4, 6, 22, 4, 5, 25,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>conducted info dissemination re covid at bound...</td>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>[[7, 6, 13, 10, 18, 7, 5, 3, 10, 4, 9, 13, 22,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>may have finished counting covid so that every...</td>\n",
              "      <td>1</td>\n",
              "      <td>62</td>\n",
              "      <td>[[2, 12, 14, 4, 25, 12, 8, 3, 4, 22, 9, 13, 9,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Translated  ...                                            Encoded\n",
              "0                                         me to covid  ...  [[2, 3, 4, 5, 6, 4, 7, 6, 8, 9, 10, 0, 0, 0, 0...\n",
              "1   so many realizations during ecq because of cov...  ...  [[11, 6, 4, 2, 12, 13, 14, 4, 15, 3, 12, 16, 9...\n",
              "2   its like a covid covid kesa back to cejay haha...  ...  [[9, 5, 11, 4, 16, 9, 23, 3, 4, 12, 4, 7, 6, 8...\n",
              "3   while we are all fighting against covid meanwh...  ...  [[24, 25, 9, 16, 3, 4, 24, 3, 4, 12, 15, 3, 4,...\n",
              "4                       person house because of covid  ...  [[26, 3, 15, 11, 6, 13, 4, 25, 6, 18, 11, 3, 4...\n",
              "5                   i will die in stress not in covid  ...  [[9, 4, 24, 9, 16, 16, 4, 10, 9, 3, 4, 9, 13, ...\n",
              "6          i want to join case there is still a covid  ...  [[9, 4, 24, 12, 13, 5, 4, 5, 6, 4, 27, 6, 9, 1...\n",
              "7   so confiscate the akuang alcohol ml then the w...  ...  [[11, 6, 4, 7, 6, 13, 22, 9, 11, 7, 12, 5, 3, ...\n",
              "8     i choose you to be a positive from covid charrr  ...  [[9, 4, 7, 25, 6, 6, 11, 3, 4, 14, 6, 18, 4, 5...\n",
              "9                   jgh then ligo grabe covid stop na  ...  [[27, 19, 25, 4, 5, 25, 3, 13, 4, 16, 9, 19, 6...\n",
              "10  secretary presents the agencys preliminary ass...  ...  [[11, 3, 7, 15, 3, 5, 12, 15, 14, 4, 26, 15, 3...\n",
              "11  happy birthday to my favorite hooman i miss th...  ...  [[25, 12, 26, 26, 14, 4, 21, 9, 15, 5, 25, 10,...\n",
              "12  the way of the cross is still in the shrine of...  ...  [[5, 25, 3, 4, 24, 12, 14, 4, 6, 22, 4, 5, 25,...\n",
              "13  conducted info dissemination re covid at bound...  ...  [[7, 6, 13, 10, 18, 7, 5, 3, 10, 4, 9, 13, 22,...\n",
              "14  may have finished counting covid so that every...  ...  [[2, 12, 14, 4, 25, 12, 8, 3, 4, 22, 9, 13, 9,...\n",
              "\n",
              "[15 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOkeWvR9mnWh"
      },
      "source": [
        "Check the balance of the whole labelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tktrs4lLG0B",
        "outputId": "78faf979-2b6a-41ce-a899-00e313788f3c"
      },
      "source": [
        "#check how balanced the dataset is\n",
        "Counter(df['Analysis'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 7707, 1: 17520, 2: 19482})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZzYdrwWnOKD"
      },
      "source": [
        "# **Model Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhf5gyXMMITG"
      },
      "source": [
        "X = list(df['Encoded'])\n",
        "y = list(df['Analysis'])\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yOLehreMKlp"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En7V_Gm9oSCc"
      },
      "source": [
        "# **Python to Pytorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzkZW7HPMN1u"
      },
      "source": [
        "class ReviewsDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.y = Y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    \n",
        "    def __getitem__(self, idx): \n",
        "        return torch.from_numpy(self.X[idx][0].astype(np.int32)).to(device), self.y[idx], self.X[idx][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eysgWgkMPHq"
      },
      "source": [
        "train_ds = ReviewsDataset(X_train, y_train)\n",
        "valid_ds = ReviewsDataset(X_valid, y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ccx4UbX0OlYI"
      },
      "source": [
        "train_loss=list()\n",
        "validation_loss=list()\n",
        "accuracy_val=list()\n",
        "prediction=list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lChw3uHRsukX"
      },
      "source": [
        "# **Create function for Train Model and Validation Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-QYDXHiMRwi"
      },
      "source": [
        "def train_model(pretrained_weights,model, epochs, lr,saving_path):\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    #Utilization of Stochastic Gradient Descent for optimization\n",
        "    #with corresponding Learning Rate\n",
        "    best_valid_loss = float('inf')\n",
        "    optimizer = torch.optim.SGD(parameters, lr=lr)\n",
        "    best_epoch=0\n",
        "    for i in range(epochs):\n",
        "        sum_loss = 0.0\n",
        "        total = 0\n",
        "        correct=0.0\n",
        "        for x, y, l in train_dl:\n",
        "            # x is the data\n",
        "            # y is the target variable (true label)\n",
        "            # l is the label\n",
        "\n",
        "            x = x.long()\n",
        "            y = y.long().to(device)\n",
        "\n",
        "            #prediction of the model using the given data\n",
        "            y_pred = model(x, l)\n",
        "            pred = torch.max(y_pred, 1)[1]\n",
        "\n",
        "            #resetting gradients for each iteration\n",
        "            optimizer.zero_grad()\n",
        "            #using Cross Entropy for Loss calculation\n",
        "            loss = F.cross_entropy(y_pred, y).to(device)\n",
        "            #backward propagation\n",
        "            loss.backward()\n",
        "            #gradient step\n",
        "            optimizer.step()\n",
        "            #calculation of total loss value\n",
        "            sum_loss += loss.item()*y.shape[0]\n",
        "            total += y.shape[0]\n",
        "            correct += (pred == y).float().sum()\n",
        "        #return values from the validation metrics    \n",
        "        val_loss, val_acc, val_rmse = validation_metrics(model, val_dl)\n",
        "\n",
        "        #gathering the data for train loss, validation loss, accuracy\n",
        "        #for each epoch\n",
        "        train_loss.append(sum_loss/total)\n",
        "        validation_loss.append(val_loss)\n",
        "        accuracy_val.append(val_acc)\n",
        "\n",
        "        print(\"Epoch \"+str(i+1)+\": train loss %.3f, val loss %.3f, train accuracy %.3f, val accuracy %.3f, and val rmse %.3f\" % \n",
        "              (sum_loss/total, val_loss, correct/total, val_acc, val_rmse))\n",
        "        \n",
        "        if val_loss < best_valid_loss:\n",
        "          best_valid_loss = val_loss\n",
        "          best_val_acc=val_acc\n",
        "          best_epoch=i\n",
        "          torch.save({'epoch': i,\n",
        "            'pretrained_weights':pretrained_weights,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_loss': val_loss,\n",
        "            'train_loss': sum_loss/total,\n",
        "            'train_acc': correct/total,\n",
        "            'val_acc':val_acc}\n",
        "            , saving_path)\n",
        "          \n",
        "        if abs((sum_loss/total)-val_loss) >= 0.2:\n",
        "          return best_epoch\n",
        "    return best_epoch\n",
        "\n",
        "def validation_metrics (model, valid_dl):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    sum_loss = 0.0\n",
        "    sum_rmse = 0.0\n",
        "    for x, y, l in valid_dl:\n",
        "      # x is the data\n",
        "      # y is the target variable (true label)\n",
        "      # l is the label\n",
        "      x = x.long()\n",
        "      y = y.long().to(device)\n",
        "\n",
        "      #prediction of the model using the given data\n",
        "      y_hat = model(x, l)\n",
        "\n",
        "      #using Cross Entropy for Loss calculation\n",
        "      loss = F.cross_entropy(y_hat, y).to(device)\n",
        "      pred = torch.max(y_hat, 1)[1]\n",
        "\n",
        "      #collecting the prediction data for y_pred use in classification report\n",
        "      prediction.append(pred)\n",
        "\n",
        "      #calculation of total loss value and RMSE\n",
        "      correct += (pred == y).float().sum()\n",
        "      total += y.shape[0]\n",
        "      sum_loss += loss.item()*y.shape[0]\n",
        "      sum_rmse += np.sqrt(mean_squared_error(pred.cpu(), y.cpu().unsqueeze(-1)))*y.shape[0]\n",
        "    return sum_loss/total, correct/total, sum_rmse/total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXkqfKvyMUTp"
      },
      "source": [
        "batch_size = 128\n",
        "vocab_size = len(words)\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
        "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SxScz9JLq8s"
      },
      "source": [
        "# Pre-trained Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tsubfxcMWPN"
      },
      "source": [
        "def load_glove_vectors(glove_file=\"/content/gdrive/MyDrive/Colab Notebooks/glove.6B.100d.txt\"): #50, 100, 300\n",
        "    \"\"\"Load the glove word vectors\"\"\"\n",
        "    word_vectors = {}\n",
        "    with open(glove_file) as f:\n",
        "        for line in f:\n",
        "            split = line.split()\n",
        "            word_vectors[split[0]] = np.array([float(x) for x in split[1:]])\n",
        "    return word_vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OiGlZFXL2Tr"
      },
      "source": [
        "# Embedding Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqeftMA5Mgfd"
      },
      "source": [
        "def get_emb_matrix(pretrained, word_counts, emb_size = 100): #50, 100, 300\n",
        "    \"\"\" Creates embedding matrix from word vectors\"\"\"\n",
        "    vocab_size = len(word_counts) + 2\n",
        "    vocab_to_idx = {}\n",
        "    vocab = [\"\", \"UNK\"]\n",
        "    W = np.zeros((vocab_size, emb_size), dtype=\"float32\")\n",
        "    W[0] = np.zeros(emb_size, dtype='float32') # adding a vector for padding\n",
        "    W[1] = np.random.uniform(-0.25, 0.25, emb_size) # adding a vector for unknown words \n",
        "    vocab_to_idx[\"UNK\"] = 1\n",
        "    i = 2\n",
        "    for word in word_counts:\n",
        "        if word in word_vecs:\n",
        "            W[i] = word_vecs[word]\n",
        "        else:\n",
        "            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
        "        vocab_to_idx[word] = i\n",
        "        vocab.append(word)\n",
        "        i += 1   \n",
        "    return W, np.array(vocab), vocab_to_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKBJS9G_MiB9"
      },
      "source": [
        "word_vecs = load_glove_vectors()\n",
        "pretrained_weights, vocab, vocab2index = get_emb_matrix(word_vecs, counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzI4IFbdL54F"
      },
      "source": [
        "# LSTM GloVe Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XpEsuuMMjqz"
      },
      "source": [
        "class LSTM_glove_vecs(torch.nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim,num_layers, hidden_dim, dropout, glove_weights,bidirectional) :\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        #copying GloVe word embedding to model\n",
        "        self.embeddings.weight.data.copy_(torch.from_numpy(glove_weights).to(device)) \n",
        "        self.embeddings.weight.requires_grad = False ## freeze embeddings\n",
        "        #LSTM module\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "        #Linear module for the final prediction \n",
        "        #of which emotion class is the processed text\n",
        "        self.linear = nn.Linear(hidden_dim, 3)\n",
        "        #Dropout Regularization for LSTM\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x, l):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        lstm_out, (ht, ct) = self.lstm(x)\n",
        "        return self.linear(ht[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZ9KKIgYMDvr"
      },
      "source": [
        "# Declaring parameters for LSTM GloVe Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-4R6f3XMvvw"
      },
      "source": [
        "final_path='/content/gdrive/MyDrive/Best_Model_LSTM_Thesis.pt'\n",
        "\n",
        "embedding=100\n",
        "\n",
        "hidden_layers=128\n",
        "\n",
        "num_layers=3\n",
        "\n",
        "epoch=2000 \n",
        "dropout=0.3\n",
        "bidirectional=True\n",
        "\n",
        "#Loading the model with the GloVe Word Embedding and given parameters\n",
        "model = LSTM_glove_vecs(vocab_size, \n",
        "                        embedding, \n",
        "                        num_layers, \n",
        "                        hidden_layers,\n",
        "                        dropout, \n",
        "                        pretrained_weights,\n",
        "                        bidirectional)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74Gnq3BkMxd9",
        "outputId": "f79cfd68-3139-4b5a-8ac4-02d56a0e922d"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM_glove_vecs(\n",
              "  (embeddings): Embedding(29, 100, padding_idx=0)\n",
              "  (lstm): LSTM(100, 128, num_layers=3, batch_first=True, bidirectional=True)\n",
              "  (linear): Linear(in_features=128, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PcfAoaEMue1"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l5x8j-I8My6p",
        "outputId": "7c36a5b8-1c69-48ea-b941-8810fb235db9"
      },
      "source": [
        "stop_epoch=train_model(pretrained_weights, model, epochs=epoch, lr=0.6, saving_path=final_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train loss 1.033, val loss 1.034, train accuracy 0.428, val accuracy 0.441, and val rmse 1.039\n",
            "Epoch 2: train loss 1.032, val loss 1.033, train accuracy 0.430, val accuracy 0.441, and val rmse 1.039\n",
            "Epoch 3: train loss 1.031, val loss 1.031, train accuracy 0.435, val accuracy 0.451, and val rmse 1.016\n",
            "Epoch 4: train loss 1.029, val loss 1.029, train accuracy 0.441, val accuracy 0.456, and val rmse 0.988\n",
            "Epoch 5: train loss 1.028, val loss 1.028, train accuracy 0.445, val accuracy 0.463, and val rmse 0.956\n",
            "Epoch 6: train loss 1.025, val loss 1.023, train accuracy 0.454, val accuracy 0.473, and val rmse 0.991\n",
            "Epoch 7: train loss 1.021, val loss 1.022, train accuracy 0.466, val accuracy 0.501, and val rmse 0.965\n",
            "Epoch 8: train loss 1.030, val loss 1.031, train accuracy 0.433, val accuracy 0.451, and val rmse 1.028\n",
            "Epoch 9: train loss 1.029, val loss 1.030, train accuracy 0.440, val accuracy 0.453, and val rmse 1.009\n",
            "Epoch 10: train loss 1.028, val loss 1.029, train accuracy 0.445, val accuracy 0.460, and val rmse 0.907\n",
            "Epoch 11: train loss 1.026, val loss 1.026, train accuracy 0.451, val accuracy 0.467, and val rmse 0.971\n",
            "Epoch 12: train loss 1.026, val loss 1.029, train accuracy 0.450, val accuracy 0.453, and val rmse 1.015\n",
            "Epoch 13: train loss 1.027, val loss 1.028, train accuracy 0.446, val accuracy 0.453, and val rmse 0.992\n",
            "Epoch 14: train loss 1.022, val loss 1.029, train accuracy 0.461, val accuracy 0.458, and val rmse 1.007\n",
            "Epoch 15: train loss 1.022, val loss 1.030, train accuracy 0.460, val accuracy 0.442, and val rmse 0.846\n",
            "Epoch 16: train loss 1.007, val loss 1.000, train accuracy 0.490, val accuracy 0.509, and val rmse 0.972\n",
            "Epoch 17: train loss 1.003, val loss 0.998, train accuracy 0.495, val accuracy 0.510, and val rmse 0.975\n",
            "Epoch 18: train loss 0.999, val loss 0.995, train accuracy 0.501, val accuracy 0.515, and val rmse 0.959\n",
            "Epoch 19: train loss 0.996, val loss 0.993, train accuracy 0.504, val accuracy 0.516, and val rmse 0.950\n",
            "Epoch 20: train loss 0.994, val loss 0.991, train accuracy 0.507, val accuracy 0.517, and val rmse 0.939\n",
            "Epoch 21: train loss 0.992, val loss 0.989, train accuracy 0.509, val accuracy 0.518, and val rmse 0.936\n",
            "Epoch 22: train loss 0.990, val loss 0.986, train accuracy 0.509, val accuracy 0.519, and val rmse 0.941\n",
            "Epoch 23: train loss 0.988, val loss 0.984, train accuracy 0.513, val accuracy 0.519, and val rmse 0.935\n",
            "Epoch 24: train loss 0.986, val loss 0.982, train accuracy 0.514, val accuracy 0.520, and val rmse 0.929\n",
            "Epoch 25: train loss 0.984, val loss 0.982, train accuracy 0.513, val accuracy 0.521, and val rmse 0.930\n",
            "Epoch 26: train loss 0.983, val loss 0.979, train accuracy 0.517, val accuracy 0.527, and val rmse 0.929\n",
            "Epoch 27: train loss 0.980, val loss 0.976, train accuracy 0.517, val accuracy 0.525, and val rmse 0.929\n",
            "Epoch 28: train loss 0.976, val loss 0.975, train accuracy 0.522, val accuracy 0.528, and val rmse 0.915\n",
            "Epoch 29: train loss 0.971, val loss 0.967, train accuracy 0.529, val accuracy 0.536, and val rmse 0.898\n",
            "Epoch 30: train loss 0.966, val loss 0.962, train accuracy 0.534, val accuracy 0.543, and val rmse 0.897\n",
            "Epoch 31: train loss 0.960, val loss 0.951, train accuracy 0.540, val accuracy 0.556, and val rmse 0.886\n",
            "Epoch 32: train loss 0.955, val loss 0.943, train accuracy 0.544, val accuracy 0.558, and val rmse 0.883\n",
            "Epoch 33: train loss 0.946, val loss 0.937, train accuracy 0.550, val accuracy 0.561, and val rmse 0.864\n",
            "Epoch 34: train loss 0.941, val loss 0.930, train accuracy 0.551, val accuracy 0.562, and val rmse 0.865\n",
            "Epoch 35: train loss 0.934, val loss 0.922, train accuracy 0.553, val accuracy 0.566, and val rmse 0.842\n",
            "Epoch 36: train loss 0.926, val loss 0.909, train accuracy 0.558, val accuracy 0.574, and val rmse 0.864\n",
            "Epoch 37: train loss 0.917, val loss 0.905, train accuracy 0.564, val accuracy 0.575, and val rmse 0.851\n",
            "Epoch 38: train loss 0.911, val loss 0.901, train accuracy 0.566, val accuracy 0.579, and val rmse 0.859\n",
            "Epoch 39: train loss 0.905, val loss 0.891, train accuracy 0.569, val accuracy 0.583, and val rmse 0.844\n",
            "Epoch 40: train loss 0.898, val loss 0.887, train accuracy 0.576, val accuracy 0.587, and val rmse 0.848\n",
            "Epoch 41: train loss 0.892, val loss 0.885, train accuracy 0.578, val accuracy 0.588, and val rmse 0.846\n",
            "Epoch 42: train loss 0.886, val loss 0.882, train accuracy 0.581, val accuracy 0.585, and val rmse 0.832\n",
            "Epoch 43: train loss 0.881, val loss 0.880, train accuracy 0.583, val accuracy 0.588, and val rmse 0.845\n",
            "Epoch 44: train loss 0.875, val loss 0.875, train accuracy 0.588, val accuracy 0.586, and val rmse 0.823\n",
            "Epoch 45: train loss 0.869, val loss 0.877, train accuracy 0.590, val accuracy 0.591, and val rmse 0.845\n",
            "Epoch 46: train loss 0.864, val loss 0.870, train accuracy 0.594, val accuracy 0.594, and val rmse 0.838\n",
            "Epoch 47: train loss 0.856, val loss 0.869, train accuracy 0.598, val accuracy 0.593, and val rmse 0.832\n",
            "Epoch 48: train loss 0.851, val loss 0.868, train accuracy 0.600, val accuracy 0.593, and val rmse 0.838\n",
            "Epoch 49: train loss 0.841, val loss 0.851, train accuracy 0.605, val accuracy 0.601, and val rmse 0.816\n",
            "Epoch 50: train loss 0.837, val loss 0.863, train accuracy 0.607, val accuracy 0.601, and val rmse 0.846\n",
            "Epoch 51: train loss 0.831, val loss 0.852, train accuracy 0.611, val accuracy 0.604, and val rmse 0.829\n",
            "Epoch 52: train loss 0.825, val loss 0.875, train accuracy 0.615, val accuracy 0.597, and val rmse 0.826\n",
            "Epoch 53: train loss 0.818, val loss 0.851, train accuracy 0.616, val accuracy 0.605, and val rmse 0.824\n",
            "Epoch 54: train loss 0.813, val loss 0.840, train accuracy 0.622, val accuracy 0.608, and val rmse 0.828\n",
            "Epoch 55: train loss 0.808, val loss 0.843, train accuracy 0.626, val accuracy 0.608, and val rmse 0.829\n",
            "Epoch 56: train loss 0.800, val loss 0.841, train accuracy 0.626, val accuracy 0.606, and val rmse 0.828\n",
            "Epoch 57: train loss 0.793, val loss 0.845, train accuracy 0.630, val accuracy 0.611, and val rmse 0.819\n",
            "Epoch 58: train loss 0.785, val loss 0.834, train accuracy 0.637, val accuracy 0.617, and val rmse 0.825\n",
            "Epoch 59: train loss 0.777, val loss 0.844, train accuracy 0.645, val accuracy 0.617, and val rmse 0.815\n",
            "Epoch 60: train loss 0.769, val loss 0.843, train accuracy 0.649, val accuracy 0.616, and val rmse 0.820\n",
            "Epoch 61: train loss 0.759, val loss 0.827, train accuracy 0.652, val accuracy 0.620, and val rmse 0.810\n",
            "Epoch 62: train loss 0.752, val loss 0.825, train accuracy 0.659, val accuracy 0.622, and val rmse 0.810\n",
            "Epoch 63: train loss 0.740, val loss 0.848, train accuracy 0.667, val accuracy 0.620, and val rmse 0.810\n",
            "Epoch 64: train loss 0.730, val loss 0.836, train accuracy 0.672, val accuracy 0.624, and val rmse 0.818\n",
            "Epoch 65: train loss 0.720, val loss 0.838, train accuracy 0.679, val accuracy 0.623, and val rmse 0.812\n",
            "Epoch 66: train loss 0.708, val loss 0.853, train accuracy 0.680, val accuracy 0.621, and val rmse 0.799\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e7009ab6e255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-70a55589bc92>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(pretrained_weights, model, epochs, lr, saving_path)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m#calculation of total loss value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3bpuy4SPjTf"
      },
      "source": [
        "#Getting the y values (label)\n",
        "targets=list()\n",
        "for x,y,l in val_dl:\n",
        "  for z in y:\n",
        "    targets.append(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnJoz0DJZQhY"
      },
      "source": [
        "temp = 0\n",
        "for i in prediction:\n",
        "  temp+=1\n",
        "  if(len(i)< 128):\n",
        "    temp+=1\n",
        "    break\n",
        "print('prediction model indexing for validation', temp-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyQ6bLx-PnZJ"
      },
      "source": [
        "preds=list()\n",
        "temp=prediction[(stop_epoch*88):(stop_epoch*88)+88]\n",
        "for i in range (0,len(temp)):\n",
        "  for z in temp[i]:\n",
        "    preds.append(z.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0PmLhi3P3Y9"
      },
      "source": [
        "# Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjuU0eLcT0hD"
      },
      "source": [
        "#Confusion Matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_true = targets\n",
        "y_pred = preds\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}